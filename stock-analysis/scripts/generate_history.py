# -*- coding: utf-8 -*-
"""
ç”Ÿæˆå†å²è¶‹åŠ¿æ•°æ®
ä»å­˜æ¡£ä¸­è¯»å–æœ€è¿‘Nå¤©çš„æ•°æ®ï¼Œç”Ÿæˆå†å²è¶‹åŠ¿ JSON
"""
import json
import os
from datetime import date, timedelta
from pathlib import Path
from collections import defaultdict

def load_archive(archive_dir, date_str):
    """åŠ è½½æŒ‡å®šæ—¥æœŸçš„å­˜æ¡£æ•°æ®"""
    archive_file = Path(archive_dir) / f"{date_str}.json"
    if not archive_file.exists():
        return None

    try:
        with open(archive_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸  è¯»å–å­˜æ¡£ {date_str} å¤±è´¥: {e}")
        return None

def generate_main_indices_history(archives, dates):
    """
    ç”Ÿæˆä¸»è¦æŒ‡æ•°çš„å†å²OHLCæ•°æ®ï¼ˆä»archiveä¸­è¯»å–ï¼‰

    è¿”å›:
    {
        "dates": ["2025-11-01", "2025-11-02", ...],
        "main_indices": {
            "HS300": [
                {"open": 3200.5, "close": 3220.8, "low": 3195.2, "high": 3230.1, "ret": 0.006, "volume": 1800000},
                ...
            ],
            "CSI500": [...],
            "CSI1000": [...],
            "CSI2000": [...]
        }
    }
    """
    # ä¸»è¦æŒ‡æ•°åˆ—è¡¨
    main_index_codes = ['HS300', 'CSI500', 'CSI1000', 'CSI2000']

    main_indices = {code: [] for code in main_index_codes}

    for date_str in dates:
        if date_str not in archives:
            # å¦‚æœè¯¥æ—¥æœŸæ²¡æœ‰æ•°æ®,å¡«å……ç©ºæ•°æ®
            for code in main_index_codes:
                main_indices[code].append(None)
            continue

        indices = archives[date_str].get('indices', {})

        for code in main_index_codes:
            index_data = indices.get(code, {})
            if index_data and isinstance(index_data, dict):
                # æå–OHLCæ•°æ®
                main_indices[code].append({
                    'open': index_data.get('open', 0),
                    'close': index_data.get('close', 0),
                    'low': index_data.get('low', 0),
                    'high': index_data.get('high', 0),
                    'ret': index_data.get('ret', 0),
                    'volume': index_data.get('volume', 0)
                })
            else:
                # æ•°æ®ç¼ºå¤±
                main_indices[code].append(None)

    return {
        'dates': dates,
        'main_indices': main_indices
    }


def generate_main_indices_history_from_api(days=30):
    """
    ä»ä¸œæ–¹è´¢å¯ŒAPIè·å–ä¸»è¦æŒ‡æ•°çš„çœŸå®å†å²Kçº¿æ•°æ®

    å‚æ•°:
        days: è·å–æœ€è¿‘Nå¤©çš„Kçº¿æ•°æ®ï¼Œé»˜è®¤30å¤©

    è¿”å›:
    {
        "dates": ["2025-11-01", "2025-11-02", ...],
        "main_indices": {
            "HS300": [
                {"open": 3200.5, "close": 3220.8, "low": 3195.2, "high": 3230.1, "ret": 0.006, "volume": 1800000},
                ...
            ],
            "CSI500": [...],
            "CSI1000": [...],
            "CSI2000": [...]
        }
    }
    """
    print(f"ğŸ“Š ä»ä¸œæ–¹è´¢å¯ŒAPIè·å–ä¸»è¦æŒ‡æ•°å†å²Kçº¿æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")
    print("=" * 60)

    try:
        from eastmoney import fetch_index_kline
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥eastmoneyæ¨¡å—")
        return None

    # ä¸»è¦æŒ‡æ•°åˆ—è¡¨
    main_index_codes = ['HS300', 'CSI500', 'CSI1000', 'CSI2000']

    # å­˜å‚¨æ‰€æœ‰æŒ‡æ•°çš„Kçº¿æ•°æ®
    all_klines = {}
    dates_set = set()

    # è·å–æ¯ä¸ªæŒ‡æ•°çš„Kçº¿æ•°æ®
    for code in main_index_codes:
        df = fetch_index_kline(code, days=days)
        if df is not None and not df.empty:
            all_klines[code] = df
            dates_set.update(df['date'].tolist())
            print(f"  âœ… {code}: {len(df)} æ¡æ•°æ®")
        else:
            print(f"  âš ï¸  {code}: è·å–å¤±è´¥")
            all_klines[code] = None

    if not dates_set:
        print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•Kçº¿æ•°æ®")
        return None

    # æŒ‰æ—¥æœŸæ’åº
    dates = sorted(list(dates_set))

    # ç»„ç»‡æ•°æ®ç»“æ„
    main_indices = {code: [] for code in main_index_codes}

    for date_str in dates:
        for code in main_index_codes:
            if all_klines[code] is None:
                main_indices[code].append(None)
                continue

            # æŸ¥æ‰¾è¯¥æ—¥æœŸçš„æ•°æ®
            df = all_klines[code]
            row = df[df['date'] == date_str]

            if not row.empty:
                data = row.iloc[0]
                main_indices[code].append({
                    'open': float(data['open']),
                    'close': float(data['close']),
                    'low': float(data['low']),
                    'high': float(data['high']),
                    'ret': float(data['ret']),
                    'volume': float(data['volume'])
                })
            else:
                main_indices[code].append(None)

    print(f"\nâœ… Kçº¿æ•°æ®æ±‡æ€»:")
    print(f"   æ—¥æœŸèŒƒå›´: {dates[0]} ~ {dates[-1]}")
    print(f"   æ€»å¤©æ•°: {len(dates)}")

    return {
        'dates': dates,
        'main_indices': main_indices
    }

def generate_history(archive_dir, days=7):
    """
    ç”Ÿæˆæœ€è¿‘Nä¸ªäº¤æ˜“æ—¥çš„å†å²è¶‹åŠ¿æ•°æ®

    è¿”å›:
    {
        "dates": ["2025-11-01", "2025-11-02", ...],
        "market_trend": [
            {"date": "2025-11-01", "advice": "OFFENSE", "broad_strength": -0.18, "risk_on": false},
            ...
        ],
        "indices_trend": {
            "hs300": [0.006, -0.012, ...],
            "csi1000": [0.002, 0.015, ...],
            "shcomp": [0.004, -0.008, ...]
        },
        "hot_boards": [
            {
                "code": "BK1019",
                "name": "åŒ–å­¦åŸæ–™",
                "trend": [0.027, 0.035, ...],  # æ¯æ—¥æ¶¨è·Œå¹…
                "avg_score": 2.5,
                "days_on_list": 5  # è¿ç»­ä¸Šæ¦œå¤©æ•°
            },
            ...
        ],
        "board_rotation": {
            "2025-11-01": ["åŒ–å­¦åŸæ–™", "å…‰ä¼è®¾å¤‡", ...],
            ...
        }
    }
    """
    print(f"ğŸ“Š ç”Ÿæˆæœ€è¿‘ {days} ä¸ªäº¤æ˜“æ—¥çš„å†å²è¶‹åŠ¿æ•°æ®...")
    print("=" * 60)

    # è·å–å­˜æ¡£ç›®å½•ä¸­çš„æ‰€æœ‰å¯ç”¨æ—¥æœŸï¼ˆäº¤æ˜“æ—¥ï¼‰
    archive_path = Path(archive_dir)
    available_files = sorted(archive_path.glob("*.json"), reverse=True)  # å€’åºæ’åˆ—

    # æå–æ—¥æœŸå¹¶è¿‡æ»¤æ‰éæ—¥æœŸæ ¼å¼çš„æ–‡ä»¶
    all_dates = []
    for f in available_files:
        date_str = f.stem
        try:
            # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ—¥æœŸæ ¼å¼ YYYY-MM-DD
            date.fromisoformat(date_str)
            all_dates.append(date_str)
        except ValueError:
            continue

    # å–æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥
    dates = all_dates[:days]
    dates = list(reversed(dates))  # æ­£åºæ’åˆ—

    print(f"  æ‰¾åˆ° {len(all_dates)} ä¸ªäº¤æ˜“æ—¥çš„å­˜æ¡£æ•°æ®")
    print(f"  ä½¿ç”¨æœ€è¿‘ {len(dates)} ä¸ªäº¤æ˜“æ—¥")

    # åŠ è½½æ‰€æœ‰å­˜æ¡£æ•°æ®
    archives = {}
    for date_str in dates:
        data = load_archive(archive_dir, date_str)
        if data:
            archives[date_str] = data
            boards_count = len(data.get('industry_boards', [])) + len(data.get('concept_boards', []))
            if boards_count == 0:
                boards_count = len(data.get('boards', []))
            print(f"  âœ… {date_str}: {boards_count} ä¸ªæ¿å—")
        else:
            print(f"  âš ï¸  {date_str}: æ— æ³•è¯»å–æ•°æ®")

    if not archives:
        print("\nâŒ æ— å¯ç”¨çš„å†å²æ•°æ®")
        return None

    # æå–å¸‚åœºè¶‹åŠ¿
    market_trend = []
    for date_str in dates:
        if date_str in archives:
            market = archives[date_str].get('market', {})
            market_trend.append({
                'date': date_str,
                'advice': market.get('advice', 'NEUTRAL'),
                'broad_strength': market.get('broad_strength', 0),
                'risk_on': market.get('risk_on', False)
            })

    # æå–æŒ‡æ•°è¶‹åŠ¿ï¼ˆæ”¯æŒ5ä¸ªæ–°æŒ‡æ•°ï¼‰
    indices_trend = {
        'CSI100': [],     # ä¸­è¯100ï¼ˆè¶…å¤§ç›˜ï¼‰
        'HS300': [],      # æ²ªæ·±300ï¼ˆå¤§ç›˜ï¼‰
        'CSI500': [],     # ä¸­è¯500ï¼ˆä¸­ç›˜ï¼‰
        'CSI1000': [],    # ä¸­è¯1000ï¼ˆå°ç›˜ï¼‰
        'CSI2000': [],    # ä¸­è¯2000ï¼ˆå¾®ç›˜ï¼‰
        'SHCOMP': [],     # ä¸Šè¯æŒ‡æ•°
        # ä¿ç•™æ—§çš„å°å†™keyç”¨äºå…¼å®¹
        'hs300': [],
        'csi1000': [],
        'shcomp': []
    }

    for date_str in dates:
        if date_str in archives:
            indices = archives[date_str].get('indices', {})

            # æ–°çš„å¤§å†™æ ¼å¼ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
            indices_trend['CSI100'].append(indices.get('CSI100', {}).get('ret', None))
            indices_trend['HS300'].append(indices.get('HS300', {}).get('ret', None))
            indices_trend['CSI500'].append(indices.get('CSI500', {}).get('ret', None))
            indices_trend['CSI1000'].append(indices.get('CSI1000', {}).get('ret', None))
            indices_trend['CSI2000'].append(indices.get('CSI2000', {}).get('ret', None))
            indices_trend['SHCOMP'].append(indices.get('SHCOMP', {}).get('ret', None))

            # æ—§çš„å°å†™æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            indices_trend['hs300'].append(indices.get('hs300', {}).get('ret', None))
            indices_trend['csi1000'].append(indices.get('csi1000', {}).get('ret', None))
            indices_trend['shcomp'].append(indices.get('shcomp', {}).get('ret', None))
        else:
            # æ‰€æœ‰æŒ‡æ•°è®¾ä¸ºNone
            for key in indices_trend.keys():
                indices_trend[key].append(None)

    # ç»Ÿè®¡çƒ­é—¨æ¿å—ï¼ˆå‡ºç°åœ¨Top10çš„æ¿å—ï¼‰
    board_stats = defaultdict(lambda: {
        'name': '',
        'trend': [],
        'scores': [],
        'dates': []
    })

    board_rotation = {}

    for date_str in dates:
        if date_str not in archives:
            continue

        boards = archives[date_str].get('boards', [])
        top10 = boards[:10]

        # è®°å½•å½“æ—¥Top10
        board_rotation[date_str] = [b['name'] for b in top10]

        # ç»Ÿè®¡æ¯ä¸ªæ¿å—
        for board in top10:
            code = board['code']
            board_stats[code]['name'] = board['name']
            board_stats[code]['trend'].append(board['ret'])
            board_stats[code]['scores'].append(board.get('score', 0))
            board_stats[code]['dates'].append(date_str)

    # è®¡ç®—çƒ­é—¨æ¿å—ï¼ˆè‡³å°‘å‡ºç°2å¤©ï¼‰
    hot_boards = []
    for code, stats in board_stats.items():
        if len(stats['dates']) >= 2:  # è‡³å°‘å‡ºç°2å¤©
            avg_score = sum(stats['scores']) / len(stats['scores'])
            hot_boards.append({
                'code': code,
                'name': stats['name'],
                'trend': stats['trend'],
                'dates': stats['dates'],
                'avg_score': round(avg_score, 2),
                'days_on_list': len(stats['dates']),
                'avg_ret': round(sum(stats['trend']) / len(stats['trend']) * 100, 2)  # å¹³å‡æ¶¨å¹…(%)
            })

    # æŒ‰å‡ºç°å¤©æ•°å’Œå¹³å‡åˆ†æ’åº
    hot_boards.sort(key=lambda x: (x['days_on_list'], x['avg_score']), reverse=True)

    # ç”Ÿæˆä¸»è¦æŒ‡æ•°çš„å†å²OHLCæ•°æ®
    # ä¼˜å…ˆä½¿ç”¨archiveæ•°æ®ï¼Œä¿æŒä¸æ¿å—æ•°æ®çš„ä¸€è‡´æ€§
    main_indices_history = generate_main_indices_history(archives, dates)

    # ç”Ÿæˆæœ€è¿‘10å¤©çš„æ¯æ—¥è¯¦ç»†æ•°æ®
    daily_records = []
    recent_dates = dates[-10:] if len(dates) >= 10 else dates  # å–æœ€è¿‘10å¤©

    for date_str in reversed(recent_dates):  # å€’åºï¼šæœ€æ–°çš„åœ¨å‰é¢
        if date_str in archives:
            archive_data = archives[date_str]

            # æå–æ•°æ®ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
            daily_record = {
                'date': date_str,
                'market': archive_data.get('market', {}),
                'indices': archive_data.get('indices', {})
            }

            # å¤„ç†æ¿å—æ•°æ®
            if 'industry_boards' in archive_data and 'concept_boards' in archive_data:
                # æ–°æ ¼å¼ï¼šå·²ç»åˆ†ç±»å¥½äº†
                daily_record['industry_boards'] = archive_data.get('industry_boards', [])[:10]
                daily_record['concept_boards'] = archive_data.get('concept_boards', [])[:10]
            elif 'boards' in archive_data:
                # æ—§æ ¼å¼ï¼šæŒ‰æ¿å—ä»£ç åˆ†ç±»
                # BK0xxx = æ¦‚å¿µæ¿å—, BK1xxx = è¡Œä¸šæ¿å—
                boards = archive_data.get('boards', [])
                industry = []
                concept = []

                for b in boards:
                    code = b.get('code', '')

                    # å¦‚æœæœ‰æ˜ç¡®çš„ type å­—æ®µï¼Œä½¿ç”¨å®ƒ
                    if 'type' in b:
                        if b['type'] == 'concept':
                            concept.append(b)
                        else:
                            industry.append(b)
                    # å¦åˆ™æ ¹æ®æ¿å—ä»£ç å‰ç¼€åˆ¤æ–­
                    elif code.startswith('BK0'):
                        # BK0xxx é€šå¸¸æ˜¯æ¦‚å¿µæ¿å—
                        b_copy = b.copy()
                        b_copy['type'] = 'concept'
                        concept.append(b_copy)
                    elif code.startswith('BK1'):
                        # BK1xxx é€šå¸¸æ˜¯è¡Œä¸šæ¿å—
                        b_copy = b.copy()
                        b_copy['type'] = 'industry'
                        industry.append(b_copy)
                    else:
                        # æœªçŸ¥ç±»å‹ï¼Œé»˜è®¤å½’ç±»ä¸ºè¡Œä¸š
                        b_copy = b.copy()
                        b_copy['type'] = 'industry'
                        industry.append(b_copy)

                daily_record['industry_boards'] = industry[:10]
                daily_record['concept_boards'] = concept[:10]
            else:
                daily_record['industry_boards'] = []
                daily_record['concept_boards'] = []

            daily_records.append(daily_record)

    print(f"\nâœ… å†å²æ•°æ®ç»Ÿè®¡:")
    print(f"   æœ‰æ•ˆå¤©æ•°: {len(archives)}/{days}")
    print(f"   çƒ­é—¨æ¿å—: {len(hot_boards)} ä¸ª")
    print(f"   æ¯æ—¥è®°å½•: {len(daily_records)} å¤©")

    return {
        'dates': dates,
        'available_dates': list(archives.keys()),
        'market_trend': market_trend,
        'indices_trend': indices_trend,
        'main_indices_history': main_indices_history,  # æ–°å¢ï¼šä¸»è¦æŒ‡æ•°å†å²OHLCæ•°æ®
        'hot_boards': hot_boards[:20],  # Top 20
        'board_rotation': board_rotation,
        'daily_records': daily_records,  # æ–°å¢ï¼šæ¯æ—¥è¯¦ç»†æ•°æ®
        'generated_at': date.today().isoformat()
    }

def detect_new_boards(archive_dir, today_industry_boards=None, today_concept_boards=None, lookback_days=10):
    """
    æ£€æµ‹æ–°ä¸Šæ¦œçš„æ¿å—ï¼ˆå‰Nä¸ªäº¤æ˜“æ—¥éƒ½æœªè¿›å…¥å‰10ï¼‰

    å‚æ•°:
        archive_dir: å­˜æ¡£ç›®å½•
        today_industry_boards: ä»Šå¤©çš„è¡Œä¸šæ¿å—åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¸ä»å­˜æ¡£è¯»å–ï¼‰
        today_concept_boards: ä»Šå¤©çš„æ¦‚å¿µæ¿å—åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¸ä»å­˜æ¡£è¯»å–ï¼‰
        lookback_days: å›æº¯å¤©æ•°ï¼Œé»˜è®¤10ä¸ªäº¤æ˜“æ—¥

    è¿”å›:
        {
            'industry': set(['BK1019', ...]),  # æ–°ä¸Šæ¦œçš„è¡Œä¸šæ¿å—ä»£ç 
            'concept': set(['BK0961', ...])     # æ–°ä¸Šæ¦œçš„æ¦‚å¿µæ¿å—ä»£ç 
        }
    """
    # è·å–å­˜æ¡£ç›®å½•ä¸­çš„æ‰€æœ‰å¯ç”¨æ—¥æœŸï¼ˆäº¤æ˜“æ—¥ï¼‰ï¼ŒæŒ‰æ—¶é—´å€’åº
    archive_path = Path(archive_dir)
    available_files = sorted(archive_path.glob("*.json"), reverse=True)

    all_dates = []
    for f in available_files:
        date_str = f.stem
        try:
            date.fromisoformat(date_str)
            all_dates.append(date_str)
        except ValueError:
            continue

    # è·å–ä»Šå¤©çš„Top10æ¿å—ï¼ˆåˆ†ç±»å‹ï¼‰
    today_industry = set()
    today_concept = set()

    if today_industry_boards is not None and today_concept_boards is not None:
        # ä½¿ç”¨ä¼ å…¥çš„ä»Šå¤©çš„æ¿å—åˆ—è¡¨
        today_industry = {b['code'] for b in today_industry_boards[:10]}
        today_concept = {b['code'] for b in today_concept_boards[:10]}
    elif len(all_dates) > 0:
        # ä»å­˜æ¡£ä¸­è¯»å–æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰
        latest_date = all_dates[0]
        today_data = load_archive(archive_dir, latest_date)
        if not today_data:
            return {'industry': set(), 'concept': set()}

        if 'industry_boards' in today_data:
            # æ–°æ ¼å¼
            today_industry = {b['code'] for b in today_data.get('industry_boards', [])[:10]}
            today_concept = {b['code'] for b in today_data.get('concept_boards', [])[:10]}
        elif 'boards' in today_data:
            # æ—§æ ¼å¼å…¼å®¹
            for b in today_data.get('boards', [])[:10]:
                if b.get('type') == 'concept':
                    today_concept.add(b['code'])
                else:
                    today_industry.add(b['code'])
    else:
        return {'industry': set(), 'concept': set()}

    # ç»Ÿè®¡è¿‡å»Nä¸ªäº¤æ˜“æ—¥å‡ºç°åœ¨Top10çš„æ¿å—
    historical_industry = set()
    historical_concept = set()

    # å–è¿‡å»Nä¸ªäº¤æ˜“æ—¥ï¼ˆä»å­˜æ¡£ä¸­çš„æ‰€æœ‰æ—¥æœŸå¼€å§‹ï¼‰
    past_dates = all_dates[:lookback_days]

    for past_date_str in past_dates:
        past_data = load_archive(archive_dir, past_date_str)

        if past_data:
            if 'industry_boards' in past_data:
                # æ–°æ ¼å¼
                historical_industry.update(b['code'] for b in past_data.get('industry_boards', [])[:10])
                historical_concept.update(b['code'] for b in past_data.get('concept_boards', [])[:10])
            elif 'boards' in past_data:
                # æ—§æ ¼å¼
                for b in past_data.get('boards', [])[:10]:
                    if b.get('type') == 'concept':
                        historical_concept.add(b['code'])
                    else:
                        historical_industry.add(b['code'])

    # æ‰¾å‡ºæ–°ä¸Šæ¦œçš„æ¿å—ï¼ˆä»Šå¤©åœ¨Top10ï¼Œä½†è¿‡å»Nå¤©éƒ½ä¸åœ¨ï¼‰
    new_industry = today_industry - historical_industry
    new_concept = today_concept - historical_concept

    if new_industry or new_concept:
        print(f"\nğŸ†• æ£€æµ‹åˆ°æ–°ä¸Šæ¦œæ¿å—ï¼ˆå‰{lookback_days}ä¸ªäº¤æ˜“æ—¥æœªè¿›å…¥å‰10ï¼‰:")
        if new_industry:
            print(f"  - è¡Œä¸šæ¿å—: {len(new_industry)} ä¸ª")
        if new_concept:
            print(f"  - æ¦‚å¿µæ¿å—: {len(new_concept)} ä¸ª")

    return {
        'industry': new_industry,
        'concept': new_concept
    }

def save_history(history_data, output_path):
    """ä¿å­˜å†å²æ•°æ®åˆ° JSON æ–‡ä»¶"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(history_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å†å²æ•°æ®å·²ä¿å­˜: {output_path}")

def main():
    import argparse
    ap = argparse.ArgumentParser(description='ç”Ÿæˆå†å²è¶‹åŠ¿æ•°æ®')
    ap.add_argument('--archive-dir', default='site/data/archive', help='å­˜æ¡£ç›®å½•')
    ap.add_argument('--days', type=int, default=7, help='å†å²å¤©æ•°')
    ap.add_argument('--out', default='site/data/history.json', help='è¾“å‡ºæ–‡ä»¶')
    ap.add_argument('--use-api', action='store_true', help='ä½¿ç”¨ä¸œæ–¹è´¢å¯ŒAPIè·å–çœŸå®Kçº¿æ•°æ®ï¼ˆè€Œä¸æ˜¯ä»archiveè¯»å–ï¼‰')
    ap.add_argument('--kline-days', type=int, default=30, help='è·å–Kçº¿æ•°æ®çš„å¤©æ•°ï¼ˆå½“--use-apiæ—¶ä½¿ç”¨ï¼‰')
    args = ap.parse_args()

    history = generate_history(args.archive_dir, args.days)

    if history:
        # å¦‚æœä½¿ç”¨APIè·å–Kçº¿æ•°æ®ï¼Œæ›¿æ¢main_indices_history
        if args.use_api:
            print("\n" + "=" * 60)
            print("ğŸ”„ ä½¿ç”¨ä¸œæ–¹è´¢å¯ŒAPIè·å–çœŸå®Kçº¿æ•°æ®...")
            main_indices_history_api = generate_main_indices_history_from_api(days=args.kline_days)
            if main_indices_history_api:
                history['main_indices_history'] = main_indices_history_api
                print("âœ… æˆåŠŸæ›¿æ¢ä¸ºçœŸå®Kçº¿æ•°æ®")
            else:
                print("âš ï¸  APIè·å–å¤±è´¥ï¼Œä½¿ç”¨archiveæ•°æ®")

        save_history(history, args.out)

        print("\n" + "=" * 60)
        print("ğŸ“Š çƒ­é—¨æ¿å— Top 5:")
        for i, board in enumerate(history['hot_boards'][:5], 1):
            print(f"  {i}. {board['name']} - ä¸Šæ¦œ{board['days_on_list']}å¤©, å¹³å‡æ¶¨å¹…{board['avg_ret']}%")

        print("\nğŸ“Š ä¸»è¦æŒ‡æ•°Kçº¿æ•°æ®:")
        if 'main_indices_history' in history:
            mih = history['main_indices_history']
            print(f"  æ—¥æœŸèŒƒå›´: {mih['dates'][0]} ~ {mih['dates'][-1]}")
            print(f"  æ€»å¤©æ•°: {len(mih['dates'])}")
            for code in ['HS300', 'CSI500', 'CSI1000', 'CSI2000']:
                if code in mih['main_indices']:
                    valid_count = sum(1 for x in mih['main_indices'][code] if x is not None)
                    print(f"  {code}: {valid_count}/{len(mih['dates'])} æ¡æœ‰æ•ˆæ•°æ®")
    else:
        print("\nâŒ å†å²æ•°æ®ç”Ÿæˆå¤±è´¥")

if __name__ == '__main__':
    main()
