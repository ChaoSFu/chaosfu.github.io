#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨urllibè·å–ä¸œæ–¹è´¢å¯Œæ¿å—å†å²æ•°æ®ï¼ˆä¸ä¾èµ–requestsï¼‰
"""

import urllib.request
import urllib.parse
import json
from datetime import datetime, timedelta

def fetch_board_history_datacenter(board_code, board_type='industry', days=10):
    """
    å°è¯•ä½¿ç”¨æ•°æ®ä¸­å¿ƒAPIè·å–æ¿å—å†å²æ•°æ®

    å‚æ•°:
        board_code: æ¿å—ä»£ç ï¼Œå¦‚ BK0538
        board_type: 'industry' æˆ– 'concept'
        days: è·å–æœ€è¿‘Nå¤©çš„æ•°æ®
    """
    # ä¸œæ–¹è´¢å¯Œæ•°æ®ä¸­å¿ƒAPIï¼ˆæ ¹æ®ç±»ä¼¼äº§å“æ¨æµ‹ï¼‰
    base_url = "https://datacenter-web.eastmoney.com/api/data/v1/get"

    # æ¨æµ‹å‚æ•°ï¼ˆéœ€è¦å®é™…æµ‹è¯•ï¼‰
    params = {
        'reportName': 'RPT_WEB_PLATE_TREND',  # æ¿å—è¶‹åŠ¿æŠ¥è¡¨
        'columns': 'ALL',
        'filter': f'(BOARD_CODE="{board_code}")',
        'pageNumber': '1',
        'pageSize': str(days + 10),
        'sortTypes': '-1',
        'sortColumns': 'TRADE_DATE',
        'source': 'WEB',
        'client': 'WEB',
    }

    url = f"{base_url}?{urllib.parse.urlencode(params)}"

    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        }

        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=10) as response:
            content = response.read().decode('utf-8')
            data = json.loads(content)

        print(f"DEBUG [datacenter] - URL: {url[:150]}...")
        print(f"DEBUG [datacenter] - Response keys: {list(data.keys())}")

        if 'result' in data and data['result'] is not None:
            result = data['result']
            if 'data' in result:
                return result['data']

        print(f"âš ï¸  [datacenter] APIè¿”å›: {json.dumps(data, ensure_ascii=False)[:300]}")
        return []

    except Exception as e:
        print(f"âŒ [datacenter] è·å–å¤±è´¥: {e}")
        return []

def fetch_board_history(board_code, days=10):
    """
    è·å–æ¿å—å†å²Kçº¿æ•°æ®ï¼ˆä½¿ç”¨Kçº¿APIï¼‰

    å‚æ•°:
        board_code: æ¿å—ä»£ç ï¼Œå¦‚ BK0538
        days: è·å–æœ€è¿‘Nå¤©çš„æ•°æ®
    """
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days+10)  # å¤šå–å‡ å¤©ç¡®ä¿æœ‰è¶³å¤Ÿäº¤æ˜“æ—¥

    # æ„å»ºURL
    base_url = "https://push2delay.eastmoney.com/api/qt/stock/kline/get"
    params = {
        'secid': f'90.{board_code}',  # 90 = æ¿å—
        'fields1': 'f1,f2,f3,f4,f5',
        'fields2': 'f51,f52,f53,f54,f55,f56,f57,f58',
        # f51=æ—¥æœŸ, f52=å¼€ç›˜, f53=æ”¶ç›˜, f54=æœ€é«˜, f55=æœ€ä½, f56=æˆäº¤é‡, f57=æˆäº¤é¢, f58=æ¶¨è·Œå¹…
        'klt': '101',  # æ—¥K
        'fqt': '0',    # ä¸å¤æƒ
        'beg': start_date.strftime('%Y%m%d'),
        'end': end_date.strftime('%Y%m%d'),
    }

    url = f"{base_url}?{urllib.parse.urlencode(params)}"

    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        }

        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=10) as response:
            content = response.read().decode('utf-8')
            data = json.loads(content)

        print(f"DEBUG - URL: {url}")
        print(f"DEBUG - Response RC: {data.get('rc')}")
        print(f"DEBUG - Response keys: {list(data.keys())}")

        if data.get('rc') == 0 and 'data' in data:
            data_obj = data['data']
            print(f"DEBUG - Data keys: {list(data_obj.keys()) if isinstance(data_obj, dict) else 'not a dict'}")
            if isinstance(data_obj, dict):
                print(f"DEBUG - Data content: {json.dumps(data_obj, ensure_ascii=False)[:300]}")

            klines = data_obj.get('klines', []) if isinstance(data_obj, dict) else []
            print(f"DEBUG - Klines count: {len(klines)}")
            return klines
        else:
            print(f"âš ï¸  APIè¿”å›å¼‚å¸¸: {json.dumps(data, ensure_ascii=False)[:500]}")
            return []

    except Exception as e:
        print(f"âŒ è·å–å¤±è´¥: {e}")
        return []

def parse_kline(kline_str):
    """
    è§£æKçº¿å­—ç¬¦ä¸²
    æ ¼å¼: "æ—¥æœŸ,å¼€ç›˜,æ”¶ç›˜,æœ€é«˜,æœ€ä½,æˆäº¤é‡,æˆäº¤é¢,æ¶¨è·Œå¹…,..."
    """
    parts = kline_str.split(',')
    if len(parts) < 8:
        return None

    return {
        'date': parts[0],
        'open': float(parts[1]),
        'close': float(parts[2]),
        'high': float(parts[3]),
        'low': float(parts[4]),
        'volume': float(parts[5]),
        'turnover': float(parts[6]),
        'pct_change': float(parts[7]),  # æ¶¨è·Œå¹…ï¼ˆç™¾åˆ†æ¯”ï¼‰
    }

if __name__ == '__main__':
    # æµ‹è¯•ï¼šè·å–åŒ–å­¦åˆ¶å“æ¿å—çš„å†å²æ•°æ®
    print("ğŸ§ª æµ‹è¯•è·å–æ¿å—å†å²æ•°æ®...\n")

    test_code = 'BK0538'  # åŒ–å­¦åˆ¶å“

    # å…ˆå°è¯•æ•°æ®ä¸­å¿ƒAPI
    print("=" * 60)
    print("æ–¹æ³•1: æ•°æ®ä¸­å¿ƒAPI")
    print("=" * 60)
    data_center_result = fetch_board_history_datacenter(test_code, days=15)
    if data_center_result:
        print(f"âœ… æˆåŠŸï¼è·å–åˆ° {len(data_center_result)} æ¡æ•°æ®")
        if len(data_center_result) > 0:
            print(f"ç¤ºä¾‹æ•°æ®: {json.dumps(data_center_result[0], ensure_ascii=False, indent=2)}")
    else:
        print("æœªè·å–åˆ°æ•°æ®\n")

    # å†å°è¯•Kçº¿API
    print("\n" + "=" * 60)
    print("æ–¹æ³•2: Kçº¿API")
    print("=" * 60)
    klines = fetch_board_history(test_code, days=15)

    print(f"æ¿å—ä»£ç : {test_code}")
    print(f"è·å–åˆ° {len(klines)} æ¡Kçº¿æ•°æ®\n")

    if klines:
        print("æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥:")
        for kline_str in klines[-5:]:
            kline = parse_kline(kline_str)
            if kline:
                print(f"  {kline['date']}: æ¶¨è·Œå¹… {kline['pct_change']:.2f}%, æˆäº¤é¢ {kline['turnover']/1e8:.2f}äº¿")
